# document_processor.py
# from typing import List
# from langchain_core.documents import Document
# from langchain_community.document_loaders import PyPDFLoader
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from config import Config

# class DocumentProcessor:
#     """PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• """
    
#     def __init__(self, chunk_size: int = Config.CHUNK_SIZE, 
#                  chunk_overlap: int = Config.CHUNK_OVERLAP):
#         self.text_splitter = RecursiveCharacterTextSplitter(
#             chunk_size=chunk_size,
#             chunk_overlap=chunk_overlap,
#             length_function=len,
#             separators=["\n\n", "\n", " ", ""]
#         )
    
#     def load_and_split_pdf(self, pdf_path: str, book_name: str) -> List[Document]:
#         """PDFë¥¼ ë¡œë“œí•˜ê³  í˜ì´ì§€ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì²­í¬ë¡œ ë¶„í• """
#         print(f"ğŸ“– PDF ë¡œë”© ì¤‘: {pdf_path}")
        
#         loader = PyPDFLoader(pdf_path)
#         pages = loader.load()
        
#         # ê° í˜ì´ì§€ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ë©´ì„œ í˜ì´ì§€ ë²ˆí˜¸ ìœ ì§€
#         all_chunks = []
#         for page_num, page in enumerate(pages, start=1):
#             chunks = self.text_splitter.split_text(page.page_content)
            
#             for chunk_idx, chunk in enumerate(chunks):
#                 doc = Document(
#                     page_content=chunk,
#                     metadata={
#                         "book_name": book_name,
#                         "page": page_num,
#                         "chunk_index": chunk_idx,
#                         "source": pdf_path
#                     }
#                 )
#                 all_chunks.append(doc)
        
#         print(f"âœ… ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„± (í˜ì´ì§€: {len(pages)})")
#         return all_chunks

from typing import List
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
import fitz  # PyMuPDF
from config import Config

class DocumentProcessor:
    """PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì¢Œí‘œì™€ í•¨ê»˜ ì²­í¬ë¡œ ë¶„í• """
    def __init__(self, chunk_size: int = Config.CHUNK_SIZE,
                chunk_overlap: int = Config.CHUNK_OVERLAP):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\\n\\n", "\\n", " ", ""]
        )

    def load_and_split_pdf(self, pdf_path: str, book_name: str) -> List[Document]:
        """PDF ë¡œë“œ + ì¢Œí‘œ ì¶”ì¶œ + ì²­í¬ ë¶„í• """
        print(f"ğŸ“– PDF ë¡œë”© ì¤‘: {pdf_path}")

        pdf_document = fitz.open(pdf_path)
        all_chunks = []

        for page_num in range(len(pdf_document)):
            page = pdf_document[page_num]

            # í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            page_text = page.get_text()

            # ë‹¨ì–´ë³„ ì¢Œí‘œ ì¶”ì¶œ (ë‚˜ì¤‘ì— ë§¤ì¹­ìš©)
            words = page.get_text("words")  # (x0, y0, x1, y1, "word", ...)

            # ì²­í¬ë¡œ ë¶„í• 
            chunks = self.text_splitter.split_text(page_text)

            for chunk_idx, chunk in enumerate(chunks):
                # ğŸ”‘ ì²­í¬ì˜ bounding box ê³„ì‚°
                bbox = self._find_chunk_bbox(chunk, words)

                doc = Document(
                    page_content=chunk,
                    metadata={
                        "book_name": book_name,
                        "page": page_num + 1,
                        "chunk_index": chunk_idx,
                        "source": pdf_path,
                        # ğŸ†• ì¢Œí‘œ ì •ë³´ ì €ì¥
                        "bbox": bbox,
                        "page_width": page.rect.width,
                        "page_height": page.rect.height
                    }
                )
                all_chunks.append(doc)

        pdf_document.close()
        print(f"âœ… ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„± (ì¢Œí‘œ í¬í•¨)")
        return all_chunks

    def _find_chunk_bbox(self, chunk_text: str, words: List) -> dict:
        """ì²­í¬ì— í•´ë‹¹í•˜ëŠ” bounding box ê³„ì‚°"""
        # ì²­í¬ì˜ ì²«/ë§ˆì§€ë§‰ ëª‡ ë‹¨ì–´ë¡œ ìœ„ì¹˜ ì°¾ê¸°
        chunk_words = chunk_text.split()[:5] + chunk_text.split()[-5:]

        matching_coords = []
        for word_info in words:
            x1, y1, x2, y2, word = word_info[:5]
            if any(cw in word for cw in chunk_words):
                matching_coords.append((x1, y1, x2, y2))

        if matching_coords:
            x1 = min(c[0] for c in matching_coords)
            y1 = min(c[1] for c in matching_coords)
            x2 = max(c[2] for c in matching_coords)
            y2 = max(c[3] for c in matching_coords)

            return {
                "x1": float(x1),
                "y1": float(y1),
                "x2": float(x2),
                "y2": float(y2),
                "width": float(x2 - x1),
                "height": float(y2 - y1)
            }

        return None
