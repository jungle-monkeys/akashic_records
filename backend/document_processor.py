# document_processor.py
from typing import List
from langchain_core.documents import Document
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from config import Config

class DocumentProcessor:
    """PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• """
    
    def __init__(self, chunk_size: int = Config.CHUNK_SIZE, 
                 chunk_overlap: int = Config.CHUNK_OVERLAP):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
    
    def load_and_split_pdf(self, pdf_path: str, book_name: str) -> List[Document]:
        """PDFë¥¼ ë¡œë“œí•˜ê³  í˜ì´ì§€ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì²­í¬ë¡œ ë¶„í• """
        print(f"ğŸ“– PDF ë¡œë”© ì¤‘: {pdf_path}")
        
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()
        
        # ê° í˜ì´ì§€ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ë©´ì„œ í˜ì´ì§€ ë²ˆí˜¸ ìœ ì§€
        all_chunks = []
        for page_num, page in enumerate(pages, start=1):
            chunks = self.text_splitter.split_text(page.page_content)
            
            for chunk_idx, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk,
                    metadata={
                        "book_name": book_name,
                        "page": page_num,
                        "chunk_index": chunk_idx,
                        "source": pdf_path
                    }
                )
                all_chunks.append(doc)
        
        print(f"âœ… ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„± (í˜ì´ì§€: {len(pages)})")
        return all_chunks
