# problem_generator.py
from typing import List, Dict
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_core.prompts import PromptTemplate
from langchain_postgres import PGVector
from config import Config

class ProblemGenerator:
    """ë¬¸ì œ ìƒì„± ì‹œìŠ¤í…œ"""
    
    def __init__(self, vector_store: PGVector):
        self.vector_store = vector_store
        self.llm = ChatOpenAI(
            model=Config.LLM_MODEL,
            temperature=0.7,
            openai_api_key=Config.OPENAI_API_KEY
        )
        # self.llm = ChatOllama(
        #     model=Config.LLM_MODEL,
        #     base_url=Config.OLLAMA_BASE_URL,
        #     temperature=0.7
        # )
    
    def generate_keyword_problems(self, keyword: str, num_problems: int = 5) -> Dict:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì œ ìƒì„±"""
        print(f"\nğŸ” '{keyword}' í‚¤ì›Œë“œ ê´€ë ¨ ë‚´ìš© ê²€ìƒ‰ ì¤‘...")
        
        # í‚¤ì›Œë“œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.vector_store.similarity_search(keyword, k=10)
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = "\n\n".join([doc.page_content for doc in relevant_docs[:5]])
        
        # ë¬¸ì œ ìƒì„± í”„ë¡¬í”„íŠ¸
        prompt_template = """ë‹¤ìŒ êµì¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ '{keyword}' í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ {num_problems}ê°œì˜ ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

êµì¬ ë‚´ìš©:
{context}

ë¬¸ì œëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:
---
ë¬¸ì œ 1.
ìœ í˜•: [ê°ê´€ì‹/ì£¼ê´€ì‹/ì„œìˆ í˜•]
ë‚´ìš©: [ë¬¸ì œ ë‚´ìš©]
ì •ë‹µ: [ì •ë‹µ]
í•´ì„¤: [í•´ì„¤]
ë‚œì´ë„: [ìƒ/ì¤‘/í•˜]
---

ìƒì„±ëœ ë¬¸ì œë“¤:"""
        
        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["keyword", "num_problems", "context"]
        )
        
        formatted_prompt = prompt.format(
            keyword=keyword,
            num_problems=num_problems,
            context=context
        )
        
        response = self.llm.invoke(formatted_prompt)
        
        # ë ˆí¼ëŸ°ìŠ¤ ì •ë³´ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
        references = []
        seen_refs = set()
        
        for doc in relevant_docs[:5]:
            book_name = doc.metadata.get("book_name", "Unknown")
            page = doc.metadata.get("page", "Unknown")
            ref_key = f"{book_name}_{page}"
            
            if ref_key not in seen_refs:
                seen_refs.add(ref_key)
                references.append({
                    "book_name": book_name,
                    "page": page
                })
        
        return {
            "keyword": keyword,
            "problems": response.content,
            "references": references
        }
    
    def generate_style_based_problems(self, example_problems: str, num_problems: int = 5) -> Dict:
        """ìœ í˜• ê¸°ë°˜ ë¬¸ì œ ìƒì„± (ì˜ˆ: ì¡±ë³´ ìŠ¤íƒ€ì¼)"""
        print(f"\nğŸ“ ì œê³µëœ ë¬¸ì œ ìœ í˜• ë¶„ì„ ì¤‘...")
        
        # ì˜ˆì‹œ ë¬¸ì œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keyword_prompt = """ë‹¤ìŒ ë¬¸ì œë“¤ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

{example_problems}

í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•´ì£¼ì„¸ìš”:"""
        
        keyword_extraction = self.llm.invoke(keyword_prompt.format(example_problems=example_problems))
        keywords = keyword_extraction.content.strip()
        
        # í‚¤ì›Œë“œë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.vector_store.similarity_search(keywords, k=10)
        context = "\n\n".join([doc.page_content for doc in relevant_docs[:5]])
        
        # ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ì˜ ë¬¸ì œ ìƒì„±
        style_prompt_template = """ë‹¤ìŒì€ ì´ì „ì— ì¶œì œëœ ë¬¸ì œë“¤ì…ë‹ˆë‹¤:

{example_problems}

---

ë‹¤ìŒ êµì¬ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬, ìœ„ ë¬¸ì œë“¤ê³¼ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ê³¼ ë‚œì´ë„ë¡œ {num_problems}ê°œì˜ ìƒˆë¡œìš´ ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

êµì¬ ë‚´ìš©:
{context}

---

ë¬¸ì œ ìƒì„± ì‹œ ê³ ë ¤ì‚¬í•­:
- ì¶œì œ ìŠ¤íƒ€ì¼ê³¼ í˜•ì‹ì„ ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ ìœ ì§€
- ë‚œì´ë„ë¥¼ ë¹„ìŠ·í•˜ê²Œ ì„¤ì •
- ë¬¸ì œ ìœ í˜•(ê°ê´€ì‹, ì£¼ê´€ì‹ ë“±)ì„ ë™ì¼í•˜ê²Œ ìœ ì§€
- êµì¬ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë¬¸ì œ ìƒì„±

ìƒì„±ëœ ë¬¸ì œë“¤:"""
        
        prompt = PromptTemplate(
            template=style_prompt_template,
            input_variables=["example_problems", "num_problems", "context"]
        )
        
        formatted_prompt = prompt.format(
            example_problems=example_problems,
            num_problems=num_problems,
            context=context
        )
        
        response = self.llm.invoke(formatted_prompt)
        
        # ë ˆí¼ëŸ°ìŠ¤ ì •ë³´ (ì¤‘ë³µ ì œê±°)
        references = []
        seen_refs = set()
        
        for doc in relevant_docs[:5]:
            book_name = doc.metadata.get("book_name", "Unknown")
            page = doc.metadata.get("page", "Unknown")
            ref_key = f"{book_name}_{page}"
            
            if ref_key not in seen_refs:
                seen_refs.add(ref_key)
                references.append({
                    "book_name": book_name,
                    "page": page
                })
        
        return {
            "style": "ìœ í˜• ê¸°ë°˜ (ì¡±ë³´ ìŠ¤íƒ€ì¼)",
            "extracted_keywords": keywords,
            "problems": response.content,
            "references": references
        }
